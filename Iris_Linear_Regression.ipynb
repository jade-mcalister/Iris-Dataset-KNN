{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc0SRW5P0SC7nQut6Z//+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jade-mcalister/Iris-Dataset-KNN/blob/development/Iris_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "XGuEv-23a3cd",
        "outputId": "e7e33e39-e4c8-44d5-a6ce-e648b1e586dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmask = ~np.isnan(y_test) & ~np.isnan(y_predict)\\nmeanSquaredError = mean_squared_error(y_test[mask], y_predict[mask])\\n\\nprint(\"Mean squared error: \", meanSquaredError)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#load data\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "\n",
        "# x and y represent data and target\n",
        "x = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "y = raw_df.values[1::2, 2]\n",
        "\n",
        "# convert x and y to pandas DataFrames to use dropna\n",
        "x = pd.DataFrame(x)  # convert x to DataFrame\n",
        "y = pd.DataFrame(y)  # convert y to DataFrame\n",
        "\n",
        "# use dropna to get rid of null values\n",
        "x = x.dropna(axis=1) # drop columns with missing values in x\n",
        "y = y.dropna()       # drop rows with missing values in y\n",
        "\n",
        "# Convert x and y back to NumPy arrays\n",
        "x = x.to_numpy()\n",
        "y = y.to_numpy().ravel()  # ravel to convert to 1D array\n",
        "\n",
        "\n",
        "#initializations\n",
        "class LinearRegression:\n",
        "\n",
        "  def __init__(self, learningRate=0.1, iterations=1000):\n",
        "    self.learningRate=learningRate\n",
        "    self.iterations=iterations\n",
        "    self.weights=None\n",
        "    self.bias=None\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    samples, features = x.shape\n",
        "    self.weights = np.zeros(features)\n",
        "    self.bias=0\n",
        "\n",
        "    #gradient descent\n",
        "    for i in range(self.iterations):\n",
        "      y_predict = np.dot(x, self.weights)+self.bias\n",
        "      grad_dw=(1/samples)*np.dot(x.T, (y_predict - y))\n",
        "      grad_db=(1/samples)*np.sum(y_predict - y)\n",
        "\n",
        "      self.weights -= self.learningRate*grad_dw\n",
        "      self.bias -= self.learningRate*grad_db\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.weights)+self.bias\n",
        "\n",
        " #split training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "\n",
        "#initialize/fit linear regression model\n",
        "\n",
        "linear_regression = LinearRegression(learningRate=0.1, iterations=1000)\n",
        "linear_regression.fit(x_train, y_train)\n",
        "\n",
        "y_predict = linear_regression.predict(x_test)\n",
        "\n",
        "'''\n",
        "mask = ~np.isnan(y_test) & ~np.isnan(y_predict)\n",
        "meanSquaredError = mean_squared_error(y_test[mask], y_predict[mask])\n",
        "\n",
        "print(\"Mean squared error: \", meanSquaredError)\n",
        "'''"
      ]
    }
  ]
}